<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Récupérer les offres d'emploi depuis les sites de recrutement</title>
    <link href="css/prism.css" rel="stylesheet">
    <link href="css/styles.css?v=4" rel="stylesheet">
    <link href="css/font-awesome-4.2.0/css/font-awesome.min.css" rel="stylesheet">
  </head>
  <body>
    <header class="header_top">
      <h1 class="div_row"><a href="index.html">I. RACHDI</a> 
        <span class="header_social_links">
          <a href="https://twitter.com/IssamRachdi" title="Twitter @IssamRachdi"><i class="fa fa-twitter"></i></a>
          <a href="https://github.com/herch0" title="Github"><i class="fa fa-github"></i></a>
        </span>
      </h1>
    </header>
    <div class="container">
      <main>
        <article class="article_post" itemscope itemtype="http://schema.org/BlogPosting">
          <header class="page-header">
            <h1>
              <span itemprop="name">Récupérer les offres d'emploi depuis les sites de recrutement</span>
              <time itemprop="datePublished" class="post_date" datetime="2015-10-11T20:18">11 Octobre 2015</time>
            </h1>
          </header>
          <div itemprop="articleBody" class="post_body">
            <nav class="menu_interne float-right">
              <ul>
                <li><a href="#prerequis">Pré-requis</a></li>
              </ul>
            </nav>
            <p>Dans un article précédent, on avait vu comment <a href="recuperer-donnees-avito-ma-python.html">récupérer les annonces depuis avito.ma</a>. Dans cet article, on va utiliser les même outils, mais cette fois on va explorer les sites de recrutement, et plus précisemment <a href="http://rekrute.com">rekrute.com</a> et <a href="http://emploi.ma">emploi.ma</a>.</p>
            <p>Le principe, ainsi que les outils sont les même que dans le précédent article; on envoie une requête au site, puis on récupère le contenu, après, on extrait les données qu'on veut depuis le contenu html récupéré.</p>
            <h2>Pré-requis <a href='#prerequis' name='prerequis'>&para;</a></h2>
            <p>Pour arriver à notre fin, on aura besoin des outils suivants: </p>
            <ul>
              <li>Python bien sûr, version 3.</li>
              <li>Pip, pour installer facilement nos modules.</li>
              <li>Le module <a href="https://pypi.python.org/pypi/requests">requests</a>, qui nous facilitera la tâche pour l'envoi des requêtes HTTP.</li>
              <li>Le module <a href="https://pypi.python.org/pypi/beautifulsoup4">beautifulsoup4</a>, qui nous permettra de naviguer dans le contenu html et extraire les données qui nous intéressent.</li>
            </ul>
            <p>On va donc installer ces deux modules. Avec pip, l'installation de chaque module se fait facilement en une seule ligne: </p>
            <pre><code class='language-bash'>pip3 install requests
pip3 install beautifulsoup4</code></pre>
            <h2>Exploration du site emploi.ma <a href='#emploi_ma' name='emploi_ma'>&para;</a></h2>
            <p>Commençant maintenant l'exploration du site emploi.ma.</p>
            <p>Si on fait une recherche sur les métiers de l'"Informatique, nouvelles technologies", dans la région de Casablanca, on remarquera qu'une requête GET est envoyé à la page <code>http://www.emploi.ma/recherche-jobs-maroc</code>, avec un paramètre filters qui la valeur <code>tid:31 tid:58</code>. Ce paramètre est construit de la façon suivant <code>filter=tid:[id fonction] tid:[id ville]</code></p>
            <p>On peut maintenant envoyer une requête de recherche, et récupérer nos annonces.</p>
            <pre><code class='language-python'>import requests
params = {'filters': 'tid:31 tid:58'}
emploi_ma_url = 'http://www.emploi.ma/recherche-jobs-maroc'
r = requests.get(emploi_ma_url, params=params)</code></pre>
            <p>Le contenu HTML retourné est disponible dans la propriété <code>text</code> de la réponse <code>r</code> retourné.</p>
            <p>Maintenant qu'on récupéré le contenu HTML, on va faire appel au module beautifulsoup pour parcourir le contenu retourné, et extraire les données.</p>
            <p>D'abord, on importe le module puis on crée un objet <code>BeautifulSoup</code>, en lui passant le code HTML, ainsi que le type de parseur qu'on veut utiliser.</p>
            <pre><code class='language-python'>from bs4 import BeautifulSoup as bs4
html = bs4(r.text, 'html.parser')</code></pre>
            <p>Après examination du code de la page de recherche, on remarque que les div qui contiennent les annonces ont les classes "<code>emasearch-result</code>" et "<code>job-search-result</code>", on passe donc ce sélecteur à la méthode <code class='language-python'>BeautifulSoup.select()</code> qui nous retource les éléments qui correspondent au sélecteur spécifié.</p>
            <pre><code class='language-python'>annonces = html.select('.emasearch-result.job-search-result')</code></pre>
<p>Après, on va boucler sur les éléments div récupérés, puis extraire la date, titre, lien de l'annonce, ainsi que le nom du recruteur</p>
          <pre><code class='language-python'>for annonce in annonces:
    date = annonce.find('div', class_='date search-date').string
    print(date)
    lien_annonce = annonce.find('h3', class_='title search-title').contents[1]
    titre = lien_annonce.string.strip()
    href = lien_annonce['href']
    print(titre, href)
    recruteur = annonce.find('h4', class_='recruiter-name').contents[0].string
    print(recruteur.strip())</code></pre>
            <br>
            <p>Explorons le code ligne par ligne.</p>
            <pre><code class='language-python'>date = annonce.find('div', class_='date search-date').string</code></pre>
            <p>Pour chaque annonce de la boucle, on recherche un élément <code>div</code> qui a l'attribut <code>class</code> égale à '<code>date search-date</code>'. Puis on récupère la propriété <code>string</code> de l'élément retourné, celle-ci contient le texte qui est à l'intérieur de l'élément <code>div</code>.</p>
            <pre><code class="language-python">print(date)</code></pre>
            <p>Et on affiche la date récupéré.</p>
            <pre><code class="language-python">lien_annonce = annonce.find('h3', class_='title search-title').contents[1]</code></pre>
            <p>On va maintenant récupérer le titre de l'annonce, ainsi que le lien pour la page des détails. Le titre de l'annonce est un élément <code>a</code>, qui est un descendant d'un autre élément <code>h3</code>, qui a l'attribut <code>class</code> égale à "<code>title search-title</code>". La propriété <code>contents</code> est une liste des enfants de l'élément <code>h3</code>. Le premier élément (index 0) est un retour à la ligne, l'élément <code>a</code> qui nous intéresse est le deuxième dans la liste.</p>
            <pre><code class='language-python'>titre = lien_annonce.string.strip()</code></pre>
            <p>On récupère le texte du lien qui est le titre de l'annonce.</p>
            <pre><code class='language-python'>href = lien_annonce['href']
print(titre, href)</code></pre>
            <p>Puis on récupère le lien de l'annonce. On peut récupérer la valeur d'un attribut en traitant l'élément comme un dictionnaire et en lui passant le nom de l'attribut. On récupère donc le lien depuis l'attribut <code>href</code>.</p>
            <pre><code class="language-python">recruteur = annonce.find('h4', class_='recruiter-name').contents[0].string
print(recruteur.strip())</code></pre>
<p>Même principe pour le nom du recruteur, on change juste le nom de l'élément, qui est dans ce cas un <code>h4</code>, et l'attribut <code>class</code> qui a la valeur "<code>recruiter-name</code>".</p>
          <p>Les résultats qu'on a récupéré sont ceux de la première page, pour récupérer les autres pages, on devra ajouter le paramètre <code>page</code> au dictionnaire <code>params</code> qu'on a créé au début avant d'envoyer la requête.</p>
<pre><code class='language-python'>params = {'filters': 'tid:31 tid:58', 'page': 1}</code></pre>
          </div>
        </article>
      </main>
      <section class="comments_section">
        <div id="list_comments"></div>
        <form id="form_comment" action="comments-ajx.php" method="POST" onsubmit="ajouter_comment(event)">
          <input type="hidden" id="req_action" name="req_action" value="ADD_COMMENT">
          <div class="div_col">
            <div class="div_row">
              <input type="text" id="name" name="name" placeholder="Nom">
              <input type="email" id="email" name="email" placeholder="Email">
            </div>
            <div class="div_row">
              <textarea id="commentaire" name="commentaire" placeholder="Commentaire" rows="6"></textarea>
            </div>
            <button class="btn btn-default block" id="add_comment">Ajouter commentaire</button>
          </div>
        </form>
      </section>
      <div class="clearfix"></div>
    </div>
    <script src="js/prism.js"></script>
    <script src="js/comment.js?v=2"></script>
  </body>
</html>
